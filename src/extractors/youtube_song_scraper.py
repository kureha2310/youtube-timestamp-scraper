import json
import os
import re
import csv
from datetime import datetime, timezone, timedelta
from dataclasses import asdict
from typing import List, Optional

from googleapiclient import discovery
from dotenv import load_dotenv
import pandas as pd

# MeCabã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
try:
    import MeCab
    mecab_reading = MeCab.Tagger('-Oyomi')
    print("MeCab loaded successfully")
except (ImportError, RuntimeError) as e:
    print(f"MeCab not available: {type(e).__name__}. Using simple hiragana conversion.")
    mecab_reading = None

from infoclass import VideoInfo, CommentInfo, TimeStamp
from utils import aligned_json_dump

load_dotenv()
API_KEY = os.getenv('API_KEY')
if not API_KEY:
    raise RuntimeError("`.env` ã« API_KEY ãŒã‚ã‚Šã¾ã›ã‚“ã€‚YouTube Data API v3 ã®APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")

youtube = discovery.build('youtube', 'v3', developerKey=API_KEY)

# å…¥åŠ›ãƒãƒ£ãƒ³ãƒãƒ«IDèª­ã¿è¾¼ã¿
try:
    users = json.load(open('user_ids.json', encoding='utf-8'))
except FileNotFoundError:
    print("user_ids.json ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚µãƒ³ãƒ—ãƒ«ã‚’ä½œæˆã—ã¾ã™ã€‚")
    users = ["UCxxxxxxxxxxxxxxxxxxxxxx"]
    with open('user_ids.json', 'w', encoding='utf-8') as f:
        json.dump(users, f, ensure_ascii=False, indent=2)

class EnhancedAnalyzer:
    def __init__(self):
        # ã‚¸ãƒ£ãƒ³ãƒ«åˆ¤å®šç”¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        self.vocaloid_keywords = [
            "åˆéŸ³ãƒŸã‚¯","é¡éŸ³ãƒªãƒ³","é¡éŸ³ãƒ¬ãƒ³","å·¡éŸ³ãƒ«ã‚«","MEIKO","KAITO",
            "GUMI","IA","é‡éŸ³ãƒ†ãƒˆ","ã‚¸ãƒŸãƒ¼ã‚µãƒ P","wowaka","ryo","supercell",
            "ã¿ãã¨P","ã‹ã„ã‚Šããƒ™ã‚¢","DECO*27","Neru","40mP","ãƒãƒ«ãƒ¼ãƒ³","n-buna",
            "ãƒ”ãƒã‚­ã‚ªãƒ”ãƒ¼","Chinozo","Orangestar","ã˜ã‚“","ã™ã‚Šãƒ","å…«ç‹å­P","è¶ã€…P"
        ]
        self.anime_keywords = [
            "æ¶¼å®®ãƒãƒ«ãƒ’","åƒçŸ³æ’«å­","MAHOå ‚","ã©ã†ã¶ã¤ãƒ“ã‚¹ã‚±ãƒƒãƒ„","å¹³é‡ç¶¾",
            "èŒ…åŸå®Ÿé‡Œ","å¾Œè—¤é‚‘å­","ZONE","KANA-BOON","UNISON SQUARE GARDEN",
            "AKINO","äº•ä¸Šã‚ãšã¿","ä¸­å³¶ç¾©å®Ÿ","ã•ãƒ¦ã‚Š","å¤§é»’æ‘©å­£","æ¾ä»»è°·ç”±å®Ÿ"
        ]
        self.anime_titles = [
            "God knows","æ‹æ„›ã‚µãƒ¼ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³","ã‚·ãƒ«ã‚¨ãƒƒãƒˆ","ãƒ–ãƒ«ãƒ¼ãƒãƒ¼ãƒ‰",
            "ãƒãƒ¬æ™´ã‚Œãƒ¦ã‚«ã‚¤","å›ã®çŸ¥ã‚‰ãªã„ç‰©èª","å‰µä¸–ã®ã‚¢ã‚¯ã‚¨ãƒªã‚ªãƒ³",
            "ã‚ˆã†ã“ãã‚¸ãƒ£ãƒ‘ãƒªãƒ‘ãƒ¼ã‚¯ã¸","ãŠã‚¸ãƒ£é­”å¥³ã‚«ãƒ¼ãƒ‹ãƒãƒ«",
            "ã‚·ãƒ¥ã‚¬ãƒ¼ã‚½ãƒ³ã‚°ã¨ãƒ“ã‚¿ãƒ¼ã‚¹ãƒ†ãƒƒãƒ—","Zzz","å¤¢ã‚’ã‹ãªãˆã¦ãƒ‰ãƒ©ãˆã‚‚ã‚“",
            "ãƒ©ãƒ´ã‚¡ãƒ¼ã‚º","ã‚ªãƒ¬ãƒ³ã‚¸","èŠ±ã®å¡”","ãƒŸã‚«ãƒ…ã‚­"
        ]

    def to_hiragana(self, text: str) -> str:
        """ãƒ†ã‚­ã‚¹ãƒˆã‚’ã²ã‚‰ãŒãªã«å¤‰æ›"""
        if mecab_reading:
            try:
                reading = mecab_reading.parse(text).strip()
                hiragana = ''
                for char in reading:
                    if 'ã‚¡' <= char <= 'ãƒ¶':
                        hiragana += chr(ord(char) - ord('ã‚¡') + ord('ã'))
                    elif char == 'ãƒµ':
                        hiragana += 'ã‹'
                    elif char == 'ãƒ¶':
                        hiragana += 'ã‘'
                    else:
                        hiragana += char.lower()
                return hiragana
            except:
                pass
        
        # MeCabãŒä½¿ãˆãªã„å ´åˆã®ç°¡æ˜“å¤‰æ›
        return self._simple_katakana_to_hiragana(text.lower())
    
    def _simple_katakana_to_hiragana(self, text: str) -> str:
        """ç°¡æ˜“ã‚«ã‚¿ã‚«ãƒŠâ†’ã²ã‚‰ãŒãªå¤‰æ›ï¼ˆè‹±æ•°å­—ãƒ»è¨˜å·ã‚‚å‡¦ç†ï¼‰"""
        result = ''
        for char in text:
            if 'ã‚¡' <= char <= 'ãƒ¶':
                result += chr(ord(char) - ord('ã‚¡') + ord('ã'))
            elif char == 'ãƒµ':
                result += 'ã‹'
            elif char == 'ãƒ¶':
                result += 'ã‘'
            elif 'A' <= char <= 'Z':
                result += char.lower()
            elif char in 'ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™':
                # å…¨è§’æ•°å­—ã‚’åŠè§’ã«
                result += str(ord(char) - ord('ï¼'))
            elif char in 'ï¼ˆï¼‰ï¼»ï¼½ï½›ï½':
                # å…¨è§’æ‹¬å¼§ã‚’é™¤å»
                continue
            else:
                result += char
        return result

    def detect_genre(self, title: str, artist: str) -> str:
        """ã‚¸ãƒ£ãƒ³ãƒ«ã‚’è‡ªå‹•åˆ¤å®š"""
        text = f"{title} {artist}"
        if any(k.lower() in text.lower() for k in self.vocaloid_keywords):
            return "Vocaloid"
        if any(k.lower() in text.lower() for k in self.anime_keywords):
            return "ã‚¢ãƒ‹ãƒ¡"
        if any(k.lower() in title.lower() for k in self.anime_titles):
            return "ã‚¢ãƒ‹ãƒ¡"
        return "ãã®ä»–"

    def calculate_confidence_score(self, video_info: VideoInfo) -> float:
        """æ­Œå‹•ç”»ã®ç¢ºåº¦ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ï¼ˆæ—¢å­˜ã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’æ´»ç”¨ï¼‰"""
        title = video_info.title
        description = video_info.description
        
        # æ—¢å­˜ã®is_singing_streamé–¢æ•°ã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯
        combined_text = f"{title} {description}".lower()
        singing_keywords = [
            "æ­Œ", "ã†ãŸ", "æ­Œæ ", "ã†ãŸã‚ã", "æ­Œé…ä¿¡", "singing", "sing",
            "ã‚«ãƒ©ã‚ªã‚±", "ã‹ã‚‰ãŠã‘", "karaoke",
            "éŸ³æ¥½", "music", "æ¥½æ›²", "ã‚½ãƒ³ã‚°", "song",
            "ãƒ¡ãƒ‰ãƒ¬ãƒ¼", "medley", "å¼¾ãèªã‚Š",
            "ãƒ©ã‚¤ãƒ–", "live", "æ¼”å¥", "performance",
            "ã‚¢ã‚«ãƒšãƒ©", "acappella", "ã‚³ãƒ¼ãƒ©ã‚¹", "chorus",
            "æ­Œã£ã¦ã¿ãŸ", "ã†ãŸã£ã¦ã¿ãŸ", "æ­Œãƒªãƒ¬ãƒ¼", "æ­Œå›",
            "ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ­Œ", "æ­Œç·´ç¿’", "æ–°æ›²", "cover",
            "ãƒœã‚«ãƒ­", "vocaloid", "ã‚¢ãƒ‹ã‚½ãƒ³", "anime song", "anisong",
            "ã‚»ãƒˆãƒª", "setlist", "ãƒªãƒ", "ãƒªãƒãƒ¼ã‚µãƒ«", "rehearsal"
        ]
        exclude_keywords = [
            "ã‚²ãƒ¼ãƒ ", "game", "gaming", "ãƒ—ãƒ¬ã‚¤", "play",
            "é›‘è«‡", "zatsudan", "talk", "ãŠã—ã‚ƒã¹ã‚Š", "chat",
            "æ–™ç†", "cooking", "ã‚¯ãƒƒã‚­ãƒ³ã‚°", "é£Ÿã¹ã‚‹", "eating",
            "ãŠçµµæã", "çµµ", "drawing", "art", "ã‚¤ãƒ©ã‚¹ãƒˆ",
            "å·¥ä½œ", "craft", "ä½œæ¥­", "work", "study", "å‹‰å¼·"
        ]
        
        singing_score = 0
        for keyword in singing_keywords:
            if keyword in combined_text:
                singing_score += 1
        
        exclude_score = 0
        for keyword in exclude_keywords:
            if keyword in combined_text:
                exclude_score += 1
        
        if re.search(r'[æ­Œã†ãŸã‚¦ã‚¿]', title):
            singing_score += 3
        if re.search(r'[â™ªâ™«â™¬ğŸµğŸ¶ğŸ¤ğŸ¼]', combined_text):
            singing_score += 2
        
        timestamp_count = len(re.findall(r'\d{1,2}:\d{2}', description))
        if timestamp_count >= 3:
            singing_score += 2
        
        # æ­£è¦åŒ–ã—ã¦ã‚¹ã‚³ã‚¢ã‚’0-1ã®ç¯„å›²ã«
        total_possible = len(singing_keywords) + 5 + 2  # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•° + ãƒœãƒ¼ãƒŠã‚¹ã‚¹ã‚³ã‚¢
        raw_score = max(0, singing_score - exclude_score)
        return min(1.0, raw_score / 10.0)  # 10ç‚¹æº€ç‚¹ã§æ­£è¦åŒ–

    def clean_title(self, text: str) -> str:
        """å…ˆé ­ãƒŠãƒ³ãƒãƒªãƒ³ã‚°ã‚’é™¤å»"""
        text = re.sub(
            r"^\s*(?:\(?\s*\d+\s*\)?[\.\)ï¼š:ï¼š\-]*\s*|\[\s*\d+\]\s*)",
            "",
            text
        )
        text = re.sub(r"<br\s*/?>", " ", text, flags=re.IGNORECASE)
        return text.strip()

    def parse_song_title_artist(self, title: str) -> tuple[str, str]:
        """æ›²åã¨ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆã‚’åˆ†é›¢"""
        title = self.clean_title(title)
        
        # ã€Œæ›² / æ­Œæ‰‹ã€å½¢å¼ã§åˆ†å‰²
        parts = re.split(r"\s*/\s*", title, maxsplit=1)
        if len(parts) == 2:
            song_title, artist = parts[0].strip(), parts[1].strip()
            return song_title, artist
        else:
            return title.strip(), ""

def is_singing_stream(title: str, description: str) -> bool:
    """æ—¢å­˜ã®æ­Œå‹•ç”»åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ï¼ˆãã®ã¾ã¾ä½¿ç”¨ï¼‰"""
    combined_text = f"{title} {description}".lower()
    singing_keywords = [
        "æ­Œ", "ã†ãŸ", "æ­Œæ ", "ã†ãŸã‚ã", "æ­Œé…ä¿¡", "singing", "sing",
        "ã‚«ãƒ©ã‚ªã‚±", "ã‹ã‚‰ãŠã‘", "karaoke",
        "éŸ³æ¥½", "music", "æ¥½æ›²", "ã‚½ãƒ³ã‚°", "song",
        "ãƒ¡ãƒ‰ãƒ¬ãƒ¼", "medley", "å¼¾ãèªã‚Š",
        "ãƒ©ã‚¤ãƒ–", "live", "æ¼”å¥", "performance",
        "ã‚¢ã‚«ãƒšãƒ©", "acappella", "ã‚³ãƒ¼ãƒ©ã‚¹", "chorus",
        "æ­Œã£ã¦ã¿ãŸ", "ã†ãŸã£ã¦ã¿ãŸ", "æ­Œãƒªãƒ¬ãƒ¼", "æ­Œå›",
        "ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ­Œ", "æ­Œç·´ç¿’", "æ–°æ›²", "cover",
        "ãƒœã‚«ãƒ­", "vocaloid", "ã‚¢ãƒ‹ã‚½ãƒ³", "anime song", "anisong",
        "ã‚»ãƒˆãƒª", "setlist", "ãƒªãƒ", "ãƒªãƒãƒ¼ã‚µãƒ«", "rehearsal"
    ]
    exclude_keywords = [
        "ã‚²ãƒ¼ãƒ ", "game", "gaming", "ãƒ—ãƒ¬ã‚¤", "play",
        "é›‘è«‡", "zatsudan", "talk", "ãŠã—ã‚ƒã¹ã‚Š", "chat",
        "æ–™ç†", "cooking", "ã‚¯ãƒƒã‚­ãƒ³ã‚°", "é£Ÿã¹ã‚‹", "eating",
        "ãŠçµµæã", "çµµ", "drawing", "art", "ã‚¤ãƒ©ã‚¹ãƒˆ",
        "å·¥ä½œ", "craft", "ä½œæ¥­", "work", "study", "å‹‰å¼·"
    ]
    singing_score = 0
    for keyword in singing_keywords:
        if keyword in combined_text:
            singing_score += 1
    exclude_score = 0
    for keyword in exclude_keywords:
        if keyword in combined_text:
            exclude_score += 1
    if re.search(r'[æ­Œã†ãŸã‚¦ã‚¿]', title):
        singing_score += 3
    if re.search(r'[â™ªâ™«â™¬ğŸµğŸ¶ğŸ¤ğŸ¼]', combined_text):
        singing_score += 2
    timestamp_count = len(re.findall(r'\d{1,2}:\d{2}', description))
    if timestamp_count >= 3:
        singing_score += 2
    if singing_score >= 2 and exclude_score <= singing_score:
        return True
    elif singing_score >= 4:
        return True
    else:
        return False

def get_uploads_playlist_id(channel_id: str) -> str | None:
    """æ—¢å­˜é–¢æ•°ã‚’ãã®ã¾ã¾ä½¿ç”¨"""
    if not channel_id or not channel_id.startswith("UC"):
        return None
    try:
        resp = youtube.channels().list(
            part="contentDetails",
            id=channel_id,
            fields="items/contentDetails/relatedPlaylists/uploads"
        ).execute()
        items = resp.get("items", [])
        if not items:
            return None
        return items[0]["contentDetails"]["relatedPlaylists"]["uploads"]
    except Exception as e:
        print(f"ãƒãƒ£ãƒ³ãƒãƒ« {channel_id} ã® uploads ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆå–å¾—ã§ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def get_video_info_in_playlist(playlist_id: str) -> list[VideoInfo]:
    """æ—¢å­˜é–¢æ•°ã‚’ãã®ã¾ã¾ä½¿ç”¨"""
    video_info_list: list[VideoInfo] = []
    try:
        request = youtube.playlistItems().list(
            part="snippet",
            playlistId=playlist_id,
            maxResults=50,
            fields="nextPageToken,items/snippet(publishedAt,title,description,resourceId/videoId)"
        )
        while request:
            response = request.execute()
            items = response.get("items", [])
            for i in items:
                vi = VideoInfo.from_response_snippet(i["snippet"])
                vid = vi.id

                # --- å‹•ç”»è©³ç´°ã‚’è¿½åŠ ã§å–å¾— ---
                try:
                    details = youtube.videos().list(
                        part="liveStreamingDetails,snippet",
                        id=vid,
                        fields="items(snippet/publishedAt,liveStreamingDetails/actualStartTime)"
                    ).execute()

                    if details.get("items"):
                        item = details["items"][0]
                        vi.stream_start = item.get("liveStreamingDetails", {}).get("actualStartTime")
                        if not vi.stream_start:
                            vi.stream_start = item["snippet"]["publishedAt"]

                except Exception as e:
                    print(f"å‹•ç”» {vid} ã®è©³ç´°å–å¾—ã§ã‚¨ãƒ©ãƒ¼: {e}")

                video_info_list.append(vi)

            request = youtube.playlistItems().list_next(request, response)
    except Exception as e:
        print(f"ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆ {playlist_id} ã®å–å¾—ã§ã‚¨ãƒ©ãƒ¼: {e}")
    return video_info_list

def get_comments(video_id: str) -> list[CommentInfo]:
    """æ—¢å­˜é–¢æ•°ã‚’ãã®ã¾ã¾ä½¿ç”¨"""
    comment_list: list[CommentInfo] = []
    comment_field = "snippet(videoId,textDisplay,textOriginal)"
    top_comment_f = f"items/snippet/topLevelComment/{comment_field}"
    replies_f = f"items/replies/comments/{comment_field}"

    try:
        request = youtube.commentThreads().list(
            part="snippet,replies",
            maxResults=100,
            videoId=video_id,
            fields=f"nextPageToken,{top_comment_f},{replies_f}"
        )
        while request:
            response = request.execute()
            for item in response.get("items", []):
                comment_list.extend(CommentInfo.response_item_to_comments(item))
            request = youtube.commentThreads().list_next(request, response)
    except Exception as e:
        print(f"å‹•ç”» {video_id} ã®ã‚³ãƒ¡ãƒ³ãƒˆå–å¾—ã§ã‚¨ãƒ©ãƒ¼: {e}")

    return comment_list

def main():
    print("ğŸµ YouTubeæ­Œå‹•ç”»ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—æŠ½å‡ºãƒ„ãƒ¼ãƒ«ï¼ˆçµ±åˆç‰ˆï¼‰")
    print("=" * 60)
    
    analyzer = EnhancedAnalyzer()
    
    # 1. å‹•ç”»æƒ…å ±å–å¾—ï¼ˆæ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
    uploads_ids: list[str] = []
    for uc in users:
        up = get_uploads_playlist_id(uc)
        if up:
            uploads_ids.append(up)
        else:
            print(f"å–å¾—å¤±æ•—: {uc}")

    video_info_list: list[VideoInfo] = []
    for upid in uploads_ids:
        video_info_list += get_video_info_in_playlist(upid)

    # 2. æ­Œå‹•ç”»ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    filtered_video_list = []
    for vi in video_info_list:
        if is_singing_stream(vi.title, vi.description):
            filtered_video_list.append(vi)

    print(f"å…¨å‹•ç”»æ•°: {len(video_info_list)}, æ­Œæ å‹•ç”»æ•°: {len(filtered_video_list)}")

    print("\n=== æ­Œæ ã¨ã—ã¦æ¤œå‡ºã•ã‚ŒãŸå‹•ç”» ===")
    for i, vi in enumerate(filtered_video_list[:10]):
        print(f"{i+1}. {vi.title}")
    if len(filtered_video_list) > 10:
        print(f"... ä»– {len(filtered_video_list) - 10} ä»¶")

    # 3. ã‚³ãƒ¡ãƒ³ãƒˆå–å¾—
    print("\nã‚³ãƒ¡ãƒ³ãƒˆã‚’å–å¾—ä¸­...")
    for i, video_info in enumerate(filtered_video_list):
        print(f"{i+1}/{len(filtered_video_list)}: {video_info.title}")
        video_info.comments = get_comments(video_info.id)

    # 4. ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—æŠ½å‡º
    print("\nã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’æŠ½å‡ºä¸­...")
    all_timestamps = []
    for v in filtered_video_list:
        ts_list = TimeStamp.from_videoinfo(v)
        all_timestamps.extend(ts_list)
    
    print(f"æŠ½å‡ºã•ã‚ŒãŸã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—æ•°: {len(all_timestamps)}")

    # 5. CSVå½¢å¼ã«å¤‰æ›
    print("\nCSVå½¢å¼ã«å¤‰æ›ä¸­...")
    rows = []
    seen = {}
    idx = 1

    for entry in all_timestamps:
        video_id = entry.video_id
        raw_title = entry.text
        timestamp = entry.timestamp
        published_at = getattr(entry, 'stream_start', None) or entry.published_at
        
        # ç¢ºåº¦ã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆè©²å½“ã™ã‚‹å‹•ç”»ã‚’è¦‹ã¤ã‘ã¦è¨ˆç®—ï¼‰
        confidence = 0.0
        for vi in filtered_video_list:
            if vi.id == video_id:
                confidence = analyzer.calculate_confidence_score(vi)
                break

        song_title, artist = analyzer.parse_song_title_artist(raw_title)

        # æ­Œæ‰‹ãªã—ã¯é™¤å¤–
        if not artist:
            continue

        # é‡è¤‡åˆ¤å®š
        key = (song_title.lower(), artist.lower(), video_id, timestamp)
        if key in seen:
            if re.match(r"^\s*\d+", raw_title):
                continue
        seen[key] = True

        # ã‚¸ãƒ£ãƒ³ãƒ«åˆ¤å®š
        genre = analyzer.detect_genre(song_title, artist)
        
        # ã²ã‚‰ãŒãªå¤‰æ›
        search_text = analyzer.to_hiragana(song_title)

        # æ—¥ä»˜ã‚’JSTã¸
        try:
            dt = datetime.fromisoformat((published_at or "").replace("Z", "+00:00"))
            date_str = dt.astimezone(timezone(timedelta(hours=9))).strftime("%Y/%m/%d")
        except Exception:
            date_str = ""

        rows.append([
            idx,
            song_title,
            artist,
            search_text,  # ã²ã‚‰ãŒãªæ¤œç´¢ç”¨
            genre,
            timestamp,
            date_str,
            video_id,
            f"{confidence:.2f}"  # ç¢ºåº¦ã‚¹ã‚³ã‚¢
        ])
        idx += 1

    # 6. CSVå‡ºåŠ›
    output_file = "song_timestamps_complete.csv"
    with open(output_file, "w", encoding="utf-8-sig", newline="") as f:
        writer = csv.writer(f)
        writer.writerow(["No","æ›²","æ­Œæ‰‹-ãƒ¦ãƒ‹ãƒƒãƒˆ","æ¤œç´¢ç”¨","ã‚¸ãƒ£ãƒ³ãƒ«","ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—","é…ä¿¡æ—¥","å‹•ç”»ID","ç¢ºåº¦ã‚¹ã‚³ã‚¢"])
        writer.writerows(rows)

    print(f"\nâœ… å®Œäº†ï¼CSVã‚’å‡ºåŠ›ã—ã¾ã—ãŸ: {output_file}")
    print(f"ğŸ“Š çµ±è¨ˆ:")
    print(f"   - å‡¦ç†ã—ãŸå‹•ç”»æ•°: {len(filtered_video_list)}")
    print(f"   - æŠ½å‡ºã—ãŸã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—æ•°: {len(all_timestamps)}")
    print(f"   - æœ€çµ‚å‡ºåŠ›è¡Œæ•°: {len(rows)}")
    
    # ç¢ºåº¦ã‚¹ã‚³ã‚¢çµ±è¨ˆ
    if rows:
        scores = [float(row[8]) for row in rows]
        high_conf = len([s for s in scores if s > 0.7])
        med_conf = len([s for s in scores if 0.4 <= s <= 0.7])
        low_conf = len([s for s in scores if s < 0.4])
        
        print(f"   - é«˜ç¢ºåº¦ (>0.7): {high_conf}ä»¶")
        print(f"   - ä¸­ç¢ºåº¦ (0.4-0.7): {med_conf}ä»¶")  
        print(f"   - ä½ç¢ºåº¦ (<0.4): {low_conf}ä»¶")

    # JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚‚ä¿å­˜ï¼ˆãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ç”¨ï¼‰
    vi_dict = [asdict(vi) for vi in filtered_video_list]
    aligned_json_dump(vi_dict, "comment_info.json")
    print(f"ğŸ“„ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—JSONã‚‚ä½œæˆ: comment_info.json")

if __name__ == "__main__":
    main()